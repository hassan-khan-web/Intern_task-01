The Analysis is performed on "Mall Customer Segmentation Data" Dataset.

1. Missing Values:
After checking the dataset, it was confirmed that there were no missing values in any column, so no action was needed to handle null entries.

3. Duplicate Records:
No duplicate rows were found in the dataset. Every entry was unique, so no duplicates had to be removed.

4. Standardizing Headers:
All column names were standardized by converting them to lowercase and removing spaces, making them cleaner and easier to work with in code.

5. Data Formatting:
There were no formatting issues in the dataset. All values were already well-aligned and consistent.

6. Renaming Columns:
Column headers were renamed to single-word or underscore-separated formats for better readability and coding convenience.

7. Data Type Check:
Each column’s data type was checked to ensure correctness, such as integers for numerical values and strings for text fields.



for reference and tools,
I used Google, YouTube, ChatGPT, Deepseek, and Google Colab.
Google and YouTube helped me find tutorials and understand Excel and GitHub.
ChatGPT and Deepseek were used for understanding code and improving the answers to interview questions.
Google Colab was used to run the Python code (link will be in the Word document).
The Excel file has two sheets — one with raw data, and the other with all cleaned and pre-processed steps applied.
